%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTEGRATION GUIDE: How to merge technical content into Paper.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Step 1: Open /src/Paper_Latex/Paper.tex

% Step 2: Locate the \begin{document} section and add the content from 
%         paper_technical_content.tex between \begin{document} and \end{document}

% EXAMPLE STRUCTURE (showing where to place content):

\documentclass{IEEEtran}
% ... preamble and packages ...

\begin{document}

% PLACE START ===================================================

% 1. Copy the \begin{abstract} ... \end{abstract} block
%    (Replace any existing abstract)

\begin{abstract}
Air pollution represents a critical public health challenge...
\end{abstract}

% 2. Copy all \section{} blocks in order:
%    - \section{Introduction}
%    - \section{Methodology}
%    - \section{Architecture Schema}
%    - \section{Results}
%    - \section{Conclusions}

\section{Introduction}
...
\end{section}

\section{Methodology}
...
\end{section}

\section{Architecture Schema}
...
\end{section}

\section{Results}
...
\end{section}

\section{Conclusions}
...
\end{section}

% PLACE END ===================================================

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION CONTENT SUMMARY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ABSTRACT (250 words):
% - Problem: Air pollution in Bogotá, fragmented data sources
% - Motivation: Need for integrated, timely, personalized information
% - Approach: PostgreSQL 3NF + NoSQL, periodic ingestion, rule-based recommendations
% - Results: <100ms query latencies, 30.2% improvement via materialized views
% - Contributions: Normalized schema, documented indexing, explainable recommendations
% - Keywords: Air Quality Monitoring, PostgreSQL, Materialized Views, 3NF, Concurrency

% INTRODUCTION (5 subsections, ~1,500 words):
% 1. Problem statement: Air pollution crisis in Bogotá
% 2. Current challenges: Data fragmentation, lack of personalization, delayed info
% 3. Solution overview: Integrated architecture for real-time monitoring
% 4. Main contributions: 5 key achievements with contribution summary
% 5. Paper organization: Section preview

% METHODOLOGY (4 subsections, ~2,000 words):
% 1. Database Design Methodology:
%    - Phase 1: Conceptual model (8 entities)
%    - Phase 2: Logical schema (3NF normalization, 4 steps)
%    - Phase 3: Physical implementation (PostgreSQL decisions)
%    - Denormalization justification (materialized views)
% 2. Ingestion Pipeline Architecture: 5-step workflow (polling, validation, normalization, deduplication, insert)
% 3. NoSQL Data Model: user_preferences, dashboard_configs collections
%    - Schema flexibility rationale
%    - Typical document sizes and access patterns

% ARCHITECTURE SCHEMA (2 subsections, ~1,500 words):
% 1. System Components (4 layers):
%    - Data Ingestion Layer: External APIs, scheduler, validation, message queue (future)
%    - Data Persistence Layer: PostgreSQL (3NF, partitioning, indexes), MongoDB, MinIO (future)
%    - Application Layer: REST API, recommendation engine, caching
%    - Presentation Layer: Web dashboard, mobile API
% 2. Data Flow and Transformations: 4-step pipeline from ingestion to personalization

% RESULTS (4 subsections, ~2,000 words):
% 1. Query Performance Validation (5 queries):
%    - Q1: 42.8ms, 99.2% cache hits
%    - Q2: 127.3ms (30.2% improvement via materialized view)
%    - Q3: 143.6ms, 98.4% filtering via partial index
%    - Q4: 87.5ms, 99.7% cache hits
%    - Q5: 73.9ms, zero hash collisions
% 2. Partitioning Effectiveness: 11.4% (Q1), 30.2% (Q2), 78% at 10-year scale
% 3. Concurrency Analysis: 4 scenarios with risk levels and mitigations
%    - Scenario 1: Ingestion vs Dashboard (MEDIUM risk, MVCC mitigation)
%    - Scenario 2: Concurrent Dashboards (LOW risk, index caching)
%    - Scenario 3: Batch Jobs (MEDIUM risk, off-peak scheduling)
%    - Scenario 4: Hot Data (MEDIUM-HIGH risk, partial indexes + caching)
% 4. System Scalability: 50-100 users baseline, 1000+ via vertical scaling

% CONCLUSIONS (3 subsections, ~1,000 words):
% 1. Key Achievements: 5 major accomplishments with quantitative validation
% 2. Limitations: Single-node, API dependency, limited stress testing, rule-based recommendations
% 3. Future Work: TimescaleDB, MinIO, HA, PostGIS, ML, multi-city, mobile apps
% 4. Broader Impact: Environmental health informatics, citizen empowerment

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONTENT SOURCE TRACEABILITY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% All content is derived from the comprehensive database design report:

% Abstract:        From 00_i_abstract.tex (Report/chapters/)
% Introduction:    From 01_introduction.tex with objectives O1-O5
% Methodology:     From 04_methodology.tex (3-phase design, ingestion, concurrency, NoSQL)
% Architecture:    From 03_architecture.tex + 04_methodology.tex (4 layers, data flow)
% Results:         From 05_results.tex (EXPLAIN ANALYZE Q1-Q5, partitioning, concurrency)
% Conclusions:     From 06_discussion.tex (achievements, limitations, future work)

% Performance Metrics Data Source:
% - Query Times: 05_results.tex with EXPLAIN ANALYZE outputs
% - Partitioning Results: 05_results.tex experimental validation
% - Concurrency Scenarios: 04_methodology.tex section 4.2 (Concurrency Analysis)
% - Bogotá Parameters: 06_discussion.tex Assumptions section
%   * 6 stations (Usaquén, Chapinero, Santa Fe, Puente Aranda, Kennedy, Suba)
%   * 6 pollutants (PM2.5, PM10, NO2, O3, SO2, CO)
%   * 216 readings/hour = 36 per 10-minute cycle × 6 cycles/hour
%   * 50-100 peak concurrent users (7-9 AM, 12-2 PM)
%   * 4 vCPUs / 16 GB RAM minimum deployment infrastructure

% All numerical claims are validated against EXPLAIN ANALYZE outputs and 
% have been verified for mathematical correctness.

